{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Merged Raw Data to Project Data\n",
    "\n",
    "- From merged dataset to project specific dataset\n",
    "- Here filtering by cruise name\n",
    "- Export and Save Files\n",
    "- pull in collapseNoMismatch processed data (Dada2 program)\n",
    "- pull in latest Metadata Sheets from /MBON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to not include:\n",
    "drop_libs = ['AC', 'AD', 'AH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "#For illustrator import:\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dada2 Banzai Output Functions\n",
    "levels = ['Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species']\n",
    "\n",
    "def make_metadata(infile):\n",
    "    df = pd.read_csv(infile)\n",
    "    df.set_index('sample_name', inplace=True)\n",
    "    return df\n",
    "\n",
    "#Raw Read Numbers\n",
    "def make_taxa_otu_tables(infile):\n",
    "    #infile = ASV_taxa_table_all.csv\n",
    "    df = pd.read_csv(infile, sep=',')\n",
    "    df.set_index('ASV', inplace=True)\n",
    "    otu_table = df.drop(levels, axis=1)\n",
    "    taxa_table = df[levels]\n",
    "    return otu_table, taxa_table\n",
    "\n",
    "#From fasta file create pandas df of ASV and sequence\n",
    "def from_fasta_to_df(file):\n",
    "    print(file)\n",
    "    with open(file) as f:\n",
    "        Ids=[]\n",
    "        seqs =[]\n",
    "        for strline in f:\n",
    "            if strline[0]=='>':\n",
    "                Ids.append(strline[1:].strip())\n",
    "            else:\n",
    "                seqs.append(strline.strip())\n",
    "    print('Number of Ids:',len(Ids))\n",
    "    print('Number of Seqs:',len(seqs))\n",
    "    seq_dict = dict(zip(Ids, seqs))\n",
    "    #make pandas df\n",
    "    df= pd.DataFrame.from_dict(seq_dict,orient='index', columns=['sequence'])\n",
    "    return df\n",
    "\n",
    "#from metadata file, limit OTU table and taxa table to those present in those samples\n",
    "def from_metadata_to_taxareads(meta_data, otu_table, taxa_table):\n",
    "    #standard M6 output; sample_names as index; OTUs as index\n",
    "    cols = list(meta_data)\n",
    "    otu_lim = pd.concat([meta_data, otu_table.T],join='inner', axis=1)\n",
    "    otu_lim.drop(cols, inplace=True, axis=1)\n",
    "    otu_lim=otu_lim.T\n",
    "    otu_lim['Total']=otu_lim.sum(axis=1)\n",
    "    otu_lim = otu_lim.loc[otu_lim['Total']>0]\n",
    "    otu_lim.drop('Total', axis=1, inplace=True)\n",
    "    cols=list(otu_lim)\n",
    "    taxa_lim=pd.concat([otu_lim, taxa_table], axis=1, join='inner')\n",
    "    taxa_lim.drop(cols, inplace=True, axis=1)\n",
    "    return otu_lim, taxa_lim\n",
    "\n",
    "def from_taxa_to_otutab(taxa_table, otu_table):\n",
    "    #remove OTUs not in the taxa table\n",
    "    otu_lim = pd.concat([taxa_table, otu_table],join='inner', axis=1)\n",
    "    otu_lim.drop(levels, inplace=True, axis=1)\n",
    "    return otu_lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just 12S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####12S#####\n",
      "/Users/kpitz/github/MBARI-BOG/CN19S_12S/figures/\n"
     ]
    }
   ],
   "source": [
    "marker = '12S'\n",
    "\n",
    "print('#####' +marker + '#####')\n",
    "\n",
    "directory = '/Volumes/MBON/processed/banzai_Dada2/12S/Merged_dataset/Results_20211105/'\n",
    "plot_dir = '/Users/kpitz/github/MBARI-BOG/CN19S_12S/figures/'\n",
    "print(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/MBON/processed/banzai_Dada2/12S/Merged_dataset/Results_20211105/Collapsed_ASV_table_unfiltered.csv\n",
      "Number ASVs: 43248\n",
      "Number ASVs: 43248\n",
      "Number samples: 1709\n",
      "Number ASVs: 43248\n"
     ]
    }
   ],
   "source": [
    "# otu table\n",
    "file = 'Collapsed_ASV_table_unfiltered.csv'\n",
    "print(directory+file)\n",
    "df = pd.read_csv(directory + file)\n",
    "df.set_index('ASV', inplace=True)\n",
    "otu_all = df.copy()\n",
    "print('Number ASVs:', len(df.index))\n",
    "\n",
    "# taxa table\n",
    "file = 'Collapsed_taxa_table_unfiltered.csv'\n",
    "df = pd.read_csv(directory+file)\n",
    "df.set_index('ASV', inplace=True)\n",
    "taxa_all = df.copy()\n",
    "print('Number ASVs:', len(df.index))\n",
    "\n",
    "# metadata\n",
    "file = 'Collapsed_meta_table_unfiltered.csv'\n",
    "df = pd.read_csv(directory+file)\n",
    "df.set_index('sample_name', inplace=True)\n",
    "meta_all = df.copy()\n",
    "print('Number samples:', len(df.index))\n",
    "\n",
    "# sequence table\n",
    "file = 'Collapsed_seq_table_unfiltered.csv'\n",
    "df = pd.read_csv(directory +file)\n",
    "df.set_index('ASV', inplace=True)\n",
    "seq_all = df.copy()\n",
    "print('Number ASVs:', len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Area', 'Cartridge_Number', 'DNA_concentration', 'Depth', 'Depth_Class', 'ESP', 'ESP_Type', 'NOAA_DNA_ID', 'NOAA_ID', 'Num', 'PCR_settings', 'PROJECT', 'PlateID', 'Pos', 'R1', 'R2', 'SAMPLING_PI', 'SAMPLING_bottle', 'SAMPLING_campaign', 'SAMPLING_cruise', 'SAMPLING_date_time', 'SAMPLING_dec_lat', 'SAMPLING_dec_lon', 'SAMPLING_dec_long', 'SAMPLING_fluor', 'SAMPLING_institute', 'SAMPLING_platform', 'SAMPLING_platform_type', 'SAMPLING_project', 'SAMPLING_project.1', 'SAMPLING_rdepth', 'SAMPLING_real_depth', 'SAMPLING_sig_t', 'SAMPLING_station', 'SAMPLING_station_number', 'SAMPLING_transmiss_%', 'SC', 'Sample_Name', 'Sample_Order', 'Sample_Type', 'Season', 'Unnamed: 0', 'Well', 'Year', 'adapters', 'chlorophyll', 'collection_date', 'date_PCR', 'date_pcr', 'day', 'decimalLatitude', 'decimalLongitude', 'density', 'deployment_ID', 'depth', 'description', 'diss_oxygen', 'end_GMT', 'env_biome', 'env_broad_scale', 'env_feature', 'env_local_scale', 'env_material', 'env_medium', 'env_package', 'eventDate', 'extraction_ID', 'extraction_date', 'extraction_library', 'fluor', 'geo_loc_name', 'identificationReferences', 'identificationRemarks', 'investigation_type', 'label', 'lat_lon', 'library', 'library_tag_combo', 'local_time_end', 'local_time_start', 'locus', 'maximumDepthInMeters', 'mid', 'minimumDepthInMeters', 'month', 'nitrate', 'nucl_acid_amp', 'nucl_acid_ext', 'order', 'original_name', 'paired_blanks_library', 'pcr_primer_name_forward', 'pcr_primer_name_reverse', 'pcr_primer_reference', 'pcr_primers', 'pcrblank_library', 'pressure', 'pressure_dbar', 'primer_sequence_F', 'primer_sequence_R', 'primer_sequence_forward', 'primer_sequence_reverse', 'project_name', 'replicate', 's_name', 'salinity', 'samp_collect_device', 'samp_collection_device', 'samp_filter_ext_type', 'samp_filter_size_ext', 'samp_store_temp', 'samp_vol_we_dna_ext', 'sample_library', 'sample_locus', 'sample_name_well', 'sample_type', 'seqID', 'seq_meth', 'seq_notes', 'sequencing_facility', 'sop', 'start_GMT', 'tag_number', 'tag_sequence', 'target_gene', 'tdepth', 'temp', 'year', 'pcr_label']\n",
      "['CN18F' nan 'CN19S' 'KOSMOS' 'LASKER2018' '13712' '15612' '19912' '30712'\n",
      " '34812' '7213' '10013' '14213' '17113' '19613' '34413' '814' '5114'\n",
      " '7914' '11314' '14714' '17014' '19114' '32414' '12015' '13115' '15515'\n",
      " '18815' '28215' '32315' '34915' '1316' '7016' '11216' '14016' '18016'\n",
      " '22416' '24416' 'CANON16' '30616' '34916' '21511' '23611' '25511'\n",
      " 'CANON11' 'C0912' '22112' '23512' '28512' 'CN13ID' '22013' '24013'\n",
      " 'CANON13' '31613' '28014' '30214' '21515' '23715' 'CN18S' 'SBMBON'\n",
      " 'CN19F' '19620' 'CANON17S' 'CN17S' 'Lasker2018' 'Flyer2018' '308' '3808'\n",
      " '8408' '10708' '14808' 'S308' '19008' 'S408' '33808' '709' '5509' '8409'\n",
      " '12609' '17409' 'S209' '29509' '31409' '34909' '2110' '4710' '6710'\n",
      " '9010' '13810' '16110' 'S310' '30110' '35610' '1211' '6611' '10811'\n",
      " '13911' '17111' '19411' '29311' '31311' '34711' 'GOC12' '6512' '11512'\n",
      " 's408' 's209' '23208' '26208' '30308' '23009' '25209' '11710' '21410'\n",
      " '23810' '8811' '713' 'C3PO19' '917' '3917' '6617' '10717' '18017' '20017'\n",
      " '22217' '24317' '34017' '1618' '3918' '6018' '10218' '19118' '23218'\n",
      " '28418' '31018' '35218' 'S410' '22414']\n",
      "['CN19S' nan]\n",
      "['MARS' 'OFFMARS_E' nan 'C1' 'MOORING1' 'MOORING2']\n",
      "['RR' 'AT' 'AD' 'JJ' 'AC']\n",
      "Number samples: 351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAMPLING_cruise</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>SAMPLING_platform</th>\n",
       "      <th>SAMPLING_date_time</th>\n",
       "      <th>SC</th>\n",
       "      <th>PlateID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CN19Sc29_12_eDNA_RR</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>WESTERN FLYER</td>\n",
       "      <td>6/3/19 19:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19Sc29_11_eDNA_RR</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>WESTERN FLYER</td>\n",
       "      <td>6/3/19 19:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19Sc29_10_eDNA_RR</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>WESTERN FLYER</td>\n",
       "      <td>6/3/19 19:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19Sc29_9_eDNA_RR</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>WESTERN FLYER</td>\n",
       "      <td>6/3/19 19:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19Sc29_8_eDNA_RR</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>WESTERN FLYER</td>\n",
       "      <td>6/3/19 19:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19SESPMV1_SC31_eDNA_AC</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>daphne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19SESPMV1_SC29_eDNA_AC</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>daphne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19SESPMV1_SC28_eDNA_AC</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>daphne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19SESPMV1_SC26_eDNA_AC</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>daphne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN19SESPMV1_SC27_eDNA_AC</th>\n",
       "      <td>CN19S</td>\n",
       "      <td>environmental</td>\n",
       "      <td>daphne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         SAMPLING_cruise    sample_type SAMPLING_platform  \\\n",
       "sample_name                                                                 \n",
       "CN19Sc29_12_eDNA_RR                CN19S  environmental     WESTERN FLYER   \n",
       "CN19Sc29_11_eDNA_RR                CN19S  environmental     WESTERN FLYER   \n",
       "CN19Sc29_10_eDNA_RR                CN19S  environmental     WESTERN FLYER   \n",
       "CN19Sc29_9_eDNA_RR                 CN19S  environmental     WESTERN FLYER   \n",
       "CN19Sc29_8_eDNA_RR                 CN19S  environmental     WESTERN FLYER   \n",
       "...                                  ...            ...               ...   \n",
       "CN19SESPMV1_SC31_eDNA_AC           CN19S  environmental            daphne   \n",
       "CN19SESPMV1_SC29_eDNA_AC           CN19S  environmental            daphne   \n",
       "CN19SESPMV1_SC28_eDNA_AC           CN19S  environmental            daphne   \n",
       "CN19SESPMV1_SC26_eDNA_AC           CN19S  environmental            daphne   \n",
       "CN19SESPMV1_SC27_eDNA_AC           CN19S  environmental            daphne   \n",
       "\n",
       "                         SAMPLING_date_time    SC PlateID  \n",
       "sample_name                                                \n",
       "CN19Sc29_12_eDNA_RR            6/3/19 19:04   NaN      RR  \n",
       "CN19Sc29_11_eDNA_RR            6/3/19 19:04   NaN      RR  \n",
       "CN19Sc29_10_eDNA_RR            6/3/19 19:04   NaN      RR  \n",
       "CN19Sc29_9_eDNA_RR             6/3/19 19:04   NaN      RR  \n",
       "CN19Sc29_8_eDNA_RR             6/3/19 19:04   NaN      RR  \n",
       "...                                     ...   ...     ...  \n",
       "CN19SESPMV1_SC31_eDNA_AC                NaN  31.0      AC  \n",
       "CN19SESPMV1_SC29_eDNA_AC                NaN  29.0      AC  \n",
       "CN19SESPMV1_SC28_eDNA_AC                NaN  28.0      AC  \n",
       "CN19SESPMV1_SC26_eDNA_AC                NaN  26.0      AC  \n",
       "CN19SESPMV1_SC27_eDNA_AC                NaN  27.0      AC  \n",
       "\n",
       "[351 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LIMIT TO PROJECT\n",
    "# Get plate IDs that I want to pull:\n",
    "df = meta_all.copy()\n",
    "print(list(df))\n",
    "cols = ['SAMPLING_cruise','sample_type', 'SAMPLING_platform', 'SAMPLING_date_time', 'SC', 'PlateID']\n",
    "\n",
    "#print(df.index)\n",
    "print(df['SAMPLING_cruise'].unique())\n",
    "df = df.loc[df.index.str.contains('CN19S')==True]\n",
    "#df = df.loc[df['SAMPLING_cruise'].str.contains('CN19S|CN19F')==True]\n",
    "print(df['SAMPLING_cruise'].unique())\n",
    "print(df['SAMPLING_station'].unique())\n",
    "#print(df['libraryID'].unique())\n",
    "libs = df['PlateID'].unique()\n",
    "print(libs)\n",
    "print('Number samples:', len(df.index))\n",
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CN18F' nan 'CN19S' 'KOSMOS' 'LASKER2018' '13712' '15612' '19912' '30712'\n",
      " '34812' '7213' '10013' '14213' '17113' '19613' '34413' '814' '5114'\n",
      " '7914' '11314' '14714' '17014' '19114' '32414' '12015' '13115' '15515'\n",
      " '18815' '28215' '32315' '34915' '1316' '7016' '11216' '14016' '18016'\n",
      " '22416' '24416' 'CANON16' '30616' '34916' '21511' '23611' '25511'\n",
      " 'CANON11' 'C0912' '22112' '23512' '28512' 'CN13ID' '22013' '24013'\n",
      " 'CANON13' '31613' '28014' '30214' '21515' '23715' 'CN18S' 'SBMBON'\n",
      " 'CN19F' '19620' 'CANON17S' 'CN17S' 'Lasker2018' 'Flyer2018' '308' '3808'\n",
      " '8408' '10708' '14808' 'S308' '19008' 'S408' '33808' '709' '5509' '8409'\n",
      " '12609' '17409' 'S209' '29509' '31409' '34909' '2110' '4710' '6710'\n",
      " '9010' '13810' '16110' 'S310' '30110' '35610' '1211' '6611' '10811'\n",
      " '13911' '17111' '19411' '29311' '31311' '34711' 'GOC12' '6512' '11512'\n",
      " 's408' 's209' '23208' '26208' '30308' '23009' '25209' '11710' '21410'\n",
      " '23810' '8811' '713' 'C3PO19' '917' '3917' '6617' '10717' '18017' '20017'\n",
      " '22217' '24317' '34017' '1618' '3918' '6018' '10218' '19118' '23218'\n",
      " '28418' '31018' '35218' 'S410' '22414']\n",
      "['RR' 'AT' 'AD' 'JJ' 'AC']\n",
      "sample_types: ['environmental' 'negative' 'positive' 'MSU_control']\n",
      "['CN19S' nan]\n",
      "Number environmental samples: 222\n",
      "/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/Dada2_seq_data/CN19S_12S_Dada2_otu_merged.csv\n",
      "/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/Dada2_seq_data/CN19S_12S_Dada2_taxa_merged.csv\n",
      "/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/Dada2_seq_data/CN19S_12S_Dada2_seq_merged.csv\n",
      "/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/Dada2_seq_data/CN19S_12S_Dada2_meta_merged.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# USE CN19 specific metadata\n",
    "file = '/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/metadata/CN19all_CTD_ESP_sequenced_metadata_050321_annotated.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "#df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.set_index('FilterID', inplace=True)\n",
    "CN19_meta = df.copy()\n",
    "df.head()\n",
    "df = meta_all.copy()\n",
    "#print(list(df))\n",
    "cols = ['FilterID','SAMPLING_cruise','SAMPLING_station_number','SAMPLING_bottle','sample_type', 'SAMPLING_platform','ESP', 'SC', 'PlateID', 'target_gene']\n",
    "df['target_gene'] = marker\n",
    "df['FilterID'] = df.index.str.split('_').str[:-1]\n",
    "df['FilterID'] = df['FilterID'].str.join('_')\n",
    "\n",
    "#make sure match current standards:\n",
    "#fix no single digit CTD bottle numbers\n",
    "for i in range(1,10):\n",
    "    #print(i)\n",
    "    z = str(i)\n",
    "    df['FilterID'] = df['FilterID'].str.replace('_'+z+'_','_0'+z+'_' )\n",
    "\n",
    "#fix ESP names\n",
    "df['FilterID'] = df['FilterID'].str.replace('koa|Koa','KOA')\n",
    "\n",
    "#fix bongo names\n",
    "df['FilterID'] = df['FilterID'].str.replace('Bongo|BONGO', 'bongo')\n",
    "df['FilterID'] = df['FilterID'].str.replace('_bongo', 'bongo')\n",
    "df['FilterID'] = df['FilterID'].str.replace('bongo', '_bongo')\n",
    "\n",
    "\n",
    "print(df['SAMPLING_cruise'].unique())\n",
    "\n",
    "#Just the right libraries:\n",
    "print(libs)\n",
    "df = df.loc[df['PlateID'].isin(libs)==True]\n",
    "\n",
    "# REMOVE THESE LIBRARIES, SPECIFIED AT TOP\n",
    "df = df.loc[df['PlateID'].isin(drop_libs)==False]\n",
    "\n",
    "#Get the control samples:\n",
    "print('sample_types:',df['sample_type'].unique())\n",
    "controls = df.loc[df['sample_type'].isin(['environmental'])==False]\n",
    "controls = controls.loc[controls['SAMPLING_cruise']!='CN19S']  #ESP samples that might not be marked as controls\n",
    "\n",
    "#Just CN19S samples\n",
    "df = df.loc[df.index.str.contains('CN19S')==True]\n",
    "#Not C1, M1, M2\n",
    "df = df.loc[df['SAMPLING_station'].isin(['C1', 'MOORING1', 'MOORING2'])==False]\n",
    "#df = df.loc[df['SAMPLING_cruise'].str.contains('CN19S|CN19F')==True]\n",
    "print(df['SAMPLING_cruise'].unique())\n",
    "\n",
    "print('Number environmental samples:', len(df.index))\n",
    "#df = df[cols]\n",
    "df = df[['FilterID', 'target_gene', 'PlateID', 'library']]\n",
    "df = df.join(CN19_meta, on='FilterID')\n",
    "\n",
    "#check for unmerged samples:\n",
    "#df = df.loc[df['SAMPLING_cruise'].isna()==True]\n",
    "\n",
    "#now need to add back in all control samples from plates.\n",
    "\n",
    "df= pd.concat([df, controls[['sample_type', 'SC', 'ESP', 'PlateID', 'target_gene', 'FilterID', 'library']]], axis=0)\n",
    "#look it over\n",
    "df.to_csv('/Users/kpitz/Documents/test.csv')\n",
    "\n",
    "meta_project = df.copy()\n",
    "otu_project, taxa_project = from_metadata_to_taxareads(meta_project, otu_all, taxa_all)\n",
    "\n",
    "# Limit sequences to just those in otu table\n",
    "df = pd.concat([seq_all, otu_project], join='inner', axis=1)\n",
    "df = df[['sequence']]\n",
    "seq_project = df.copy()\n",
    "\n",
    "# EXPORT FOR ANALYSIS\n",
    "#export to csv files\n",
    "folder = '/Users/kpitz/github/MBARI-BOG/CN19S_12S/data/Dada2_seq_data/'\n",
    "dfs = [otu_project, taxa_project, seq_project, meta_project]\n",
    "names = ['otu', 'taxa', 'seq', 'meta']\n",
    "for df, name in zip(dfs,names):\n",
    "    df.to_csv(folder + 'CN19S_'+marker+'_Dada2_'+name+'_merged.csv')\n",
    "    print(folder + 'CN19S_'+marker+'_Dada2_'+name+'_merged.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
